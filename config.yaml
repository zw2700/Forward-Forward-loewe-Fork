seed: 42
device: "cpu"  # cpu or cuda
save: False
path_to_model: "models/test.pt"

input:
  path: datasets
  supervised: True
  batch_size: 128
  dataset: CIFAR10
  input_width: 32
  input_height: 32
  input_channels: 3
  num_classes: 10


model:
  peer_normalization: 0.03
  momentum: 0.9  # Momentum to use for the running mean in peer normalization loss.
  convolutional: True
  num_blocks: 10
  predictor_size: 8192
  reconstruction_objectives:
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10

  fully_connected:  
    num_layers_per_block: 1
    
    hidden_dim_1: 2000
    hidden_dim_2: 2000
    hidden_dim_3: 2000
    hidden_dim_4: 2000
    hidden_dim_5: 500
    hidden_dim_6: 500
    hidden_dim_7: 250
    hidden_dim_8: 250
    hidden_dim_9: 125
    hidden_dim_10: 125

  conv:
    # 3 layers
    # output_size_1: 4
    # output_size_2: 3
    # output_size_3: 2
    # kernel_size_1: 11
    # kernel_size_2: 2
    # kernel_size_3: 2
    # stride_1: 7
    # stride_2: 1
    # stride_3: 1
    # padding_1: 0
    # padding_2: 0
    # padding_3: 0
    # input_channels: 3
    # channels_1: 128
    # channels_2: 220
    # channels_3: 512

    # 5 layers
    # output_size_1: 28
    # output_size_2: 24
    # output_size_3: 8
    # output_size_4: 6
    # output_size_5: 2
    # kernel_size_1: 5
    # kernel_size_2: 5
    # kernel_size_3: 5
    # kernel_size_4: 5
    # kernel_size_5: 2
    # stride_1: 1
    # stride_2: 1
    # stride_3: 1
    # stride_4: 1
    # stride_5: 1
    # padding_1: 0
    # padding_2: 0
    # padding_3: 0
    # padding_4: 1
    # padding_5: 0
    # input_channels: 3
    # channels_1: 64
    # channels_2: 64
    # channels_3: 128
    # channels_4: 128
    # channels_5: 512

    # 8 layers
    # pool: 
    #   - 2
    #   - 4
    #   - 6
    #   - 8
    # output_size_1: 32
    # output_size_2: 32
    # output_size_3: 16
    # output_size_4: 16
    # output_size_5: 8
    # output_size_6: 8
    # output_size_7: 4
    # output_size_8: 4
    # kernel_size_1: 3
    # kernel_size_2: 3
    # kernel_size_3: 3
    # kernel_size_4: 3
    # kernel_size_5: 3
    # kernel_size_6: 3
    # kernel_size_7: 3
    # kernel_size_8: 3
    # stride_1: 1
    # stride_2: 1
    # stride_3: 1
    # stride_4: 1
    # stride_5: 1
    # stride_6: 1
    # stride_7: 1
    # stride_8: 1
    # padding_1: 1
    # padding_2: 1
    # padding_3: 1
    # padding_4: 1
    # padding_5: 1
    # padding_6: 1
    # padding_7: 1
    # padding_8: 1
    # channels_1: 10
    # channels_2: 10
    # channels_3: 20
    # channels_4: 20
    # channels_5: 40
    # channels_6: 40
    # channels_7: 80
    # channels_8: 80

    # 10 layers
    pool: 
      - 4
      - 6
      - 8
      - 10
    output_size_1: 32
    output_size_2: 32
    output_size_3: 32
    output_size_4: 32
    output_size_5: 16
    output_size_6: 16
    output_size_7: 8
    output_size_8: 8
    output_size_9: 4
    output_size_10: 4
    kernel_size_1: 3
    kernel_size_2: 3
    kernel_size_3: 3
    kernel_size_4: 3
    kernel_size_5: 3
    kernel_size_6: 3
    kernel_size_7: 3
    kernel_size_8: 3
    kernel_size_9: 3
    kernel_size_10: 3
    stride_1: 1
    stride_2: 1
    stride_3: 1
    stride_4: 1
    stride_5: 1
    stride_6: 1
    stride_7: 1
    stride_8: 1
    stride_9: 1
    stride_10: 1
    padding_1: 1
    padding_2: 1
    padding_3: 1
    padding_4: 1
    padding_5: 1
    padding_6: 1
    padding_7: 1
    padding_8: 1
    padding_9: 1
    padding_10: 1
    channels_1: 128
    channels_2: 128
    channels_3: 128
    channels_4: 256
    channels_5: 256
    channels_6: 512
    channels_7: 512
    channels_8: 512
    channels_9: 512
    channels_10: 512

training:
  epochs: 200

  learning_rate: 1e-3
  weight_decay: 3e-4
  momentum: 0.9
  dropout: 0.2
  init: He
  sim_pred:
    beta: 1  # 1 means only unsupervised loss, 0 means only prediction loss. Should be between 0 and 1 inclusively.

  downstream_learning_rate: 1e-2
  downstream_weight_decay: 3e-3
  downstream_method: "2..n"  # "n" for the final layer, "2..n" for all but first layers

  val_idx: 1  # -1: validate only once training has finished; n: validate every n epochs.


hydra:
  run:
    dir: logs

wandb:
  activate: False
  key: 973dbf755f0f765fb4a4b8f552915e484fd4131d
  project: "ff_frank_cifar"
  name: "frank"
  entity: "zw2700"
